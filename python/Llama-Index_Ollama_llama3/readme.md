Desi n-o sa intru in detalii am preluat acest [exemplu](https://docs.llamaindex.ai/en/stable/api_reference/llms/ollama/) de **Chatbot**, 

implementat pe baza:

- serverului **Ollama**, care serveste, in acest exemplu, ca
- model [***LLM***](https://klu.ai/glossary/ollama)=[**llama3**](https://www.casedone.ai/blog/ollama-beginner-guide-to-local-llm-and-api-hosting),  iar ca si integrator se foloseste
- **llama-index**

***Observatie***

   - in fisierul ***_Run.bat*** am comentat(cu **rem** i.e. remark) partea de instalare a bibiliotecilor **llama-index**, folosind utilitarul **pip**,
  deaorece instalarea trebuie facuta o singura data inainte de prima rulare.
   - am comentat pt ca in lucrul curent nu mai este necesara aceasta instalare preliminara.
