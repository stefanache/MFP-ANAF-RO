[**Langflow**](https://www.langflow.org/) va permite ca in mod visual(GUI) sa construiti [**pipe-line**](https://bytesupreme.online/crafting-no-code-local-rag-chatbots-with-langflow-and-ollama/)-*ul* AI pt ***Chatbot***-*ul* sau [**RAG**](https://bytesupreme.online/crafting-no-code-local-rag-chatbots-with-langflow-and-ollama/)-*ul* dvs construind daca vreti, intr-o maniera **descriptiva**(nedescrisa textual prin ***cod***/programare), conducta/linia de procesare([**pipeline**](https://bytesupreme.online/crafting-no-code-local-rag-chatbots-with-langflow-and-ollama/)) a aplicatiei dumnevoastra [PrivateGPT](https://github.com/ollama/ollama/tree/main/examples/langchain-python-rag-privategpt)(folosind sa spunem server-ul LLM [Ollama](https://ollama.com/download/windows)) sau de ce nu [ChatGPT](https://chatgpt.com/)-ul personal.

Ascunzand detaliile de implementare a liniei de procesare([**pipe-line**](https://bytesupreme.online/crafting-no-code-local-rag-chatbots-with-langflow-and-ollama/)), simplificand codul, **Langflow** va aduce mai multa claritate in codul dvs.

Chiar daca va trebui sa mai scrieti ceva cod, totusi lungimea codului dvs. se va scurta in mod semnificativ.

Vreau sa va mai spun ca si [**LlamaIndex**](https://docs.llamaindex.ai/en/stable/module_guides/querying/pipeline/) oferă un API de interogare(***query***) [***declarativ***](https://docs.llamaindex.ai/en/stable/getting_started/starter_tools/rag_cli/)(***fara GUI***, de aceasta data) care vă permite să înlănțuiți diferite module pentru a orchestra fluxuri de lucru simple până la avansate asupra datelor dvs(urmariti cu atentie utilizarea modulului [***QueryPipeline***](https://docs.llamaindex.ai/en/stable/module_guides/querying/pipeline/)).

Revenind la **Langflow** trebuie sa amintim si faptul ca pentru faza de *productie*, acesta are un aliat(in special in cazul proiectelor complexe) si anume *evaluatorul* [***Langfuse***](https://langfuse.com/blog/langflow)
