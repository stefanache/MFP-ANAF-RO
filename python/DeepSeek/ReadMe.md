Salut,

In acest [articol](https://api-docs.deepseek.com/news/news1226) as dori sa luam in discutie, cateva [aspecte](https://commons.wikimedia.org/wiki/File:Performance_of_AI_models_on_various_benchmarks_from_1998_to_2024.png), aflate la [confluenta](https://www.nomidl.com/natural-language-processing/difference-between-deep-learning-and-natural-language-processing/) [DL](https://www.coursera.org/articles/what-is-deep-learning?utm_medium=sem&utm_source=gg&utm_campaign=b2c_emea_x_multi_ftcof_career-academy_cx_dr_bau_gg_pmax_gc_s2_en_m_hyb_23-12_x&campaignid=20882109092&adgroupid=&device=c&keyword=&matchtype=&network=x&devicemodel=&creativeid=&assetgroupid=6485735763&targetid=&extensionid=&placement=&gad_source=1&gclid=CjwKCAiAneK8BhAVEiwAoy2HYciJfr6jl_2LKRyqAjSCuMvkwPsNSXmxGmmxSlphn2qAUs0Yyyz_sRoCH40QAvD_BwE), [NLP](https://en.wikipedia.org/wiki/Neuro-linguistic_programming) si [RT-processing](https://en.wikipedia.org/wiki/Real-time_computing), ce tin de / cu privire la [modelul](https://blog.gopenai.com/dl-models-used-in-nlp-cnn-rnns-seq-to-seq-transformers-in-depth-fec0c521e736) [**DeepSeek**](https://www.stiripesurse.ro/cutremur-in-domeniul-inteligentei-artificiale-ce-este-deepseek-si-de-ce-ii-sperie-pe-investitori_3563231.html)

Pentru inceput as vrea sa va reamintesc cate ceva despre [termenul](https://www.researchgate.net/figure/Classification-of-Cognitive-Frameworks-symbolic-connectionist-or-hybrid-Most-of-the_fig1_224133329) de ["**Inferenta/Deductie**"](https://ro.wikipedia.org/wiki/Inferen%C8%9B%C4%83)(cu/de [arhitectura cognitiva](https://creieralbastru.wordpress.com/wp-content/uploads/2010/06/ia.pdf) [simbolic-conexionistÄƒ](https://pubmed.ncbi.nlm.nih.gov/12747523/)).

[**Inferenta**](https://en.wikipedia.org/wiki/Inference) inseamna/presupune utilizarea [**modelelor AI**](https://www.liu-shen.com/Content-3151.html) in productie, pentru a lua [**decizii**](https://medium.com/@interprobeit/symbolic-ai-vs-connectionist-ai-unveiling-the-fundamental-differences-ecef3bf8063f)([Simbolism-AI](https://www.liu-shen.com/Content-3151.html)) sau pentru a face [**predicÈ›ii**](https://medium.com/@interprobeit/symbolic-ai-vs-connectionist-ai-unveiling-the-fundamental-differences-ecef3bf8063f)([Connectionist-AI](https://miro.medium.com/v2/resize:fit:1400/1*-XPNL45-GqsK1QbhXEssxw.png)).

[**Inferenta**](https://ro.wiktionary.org/wiki/inferen%C8%9B%C4%83) necesitÄƒ un numÄƒr **semnificativ**/**important**/**mare** de **GPU**-uri **NVIDIA**(utilizate in/pentru calcul-inferential, pt. construire/antrenare/invatare/training) È™i de **reÈ›ele** de **Ã®naltÄƒ performanÈ›Äƒ**([retele neuronale](https://www.aut.upt.ro/~andreea.robu/Lab1Retele.pdf) pt [antrenament/invatare](https://staff.fmi.uvt.ro/~daniela.zaharie/am2016/curs/curs12/am2016_slides12_RN.pdf)) 

[**DeepSeek**](https://huggingface.co/deepseek-ai/DeepSeek-V2) isi are radacina in performanta arhitectura actuala de baza, [**transformers**](https://www.unite.ai/ro/deepseek-v3-cum-o-pornire-chinezeasc%C4%83-de-IA-%C3%AEi-dep%C4%83%C8%99e%C8%99te-pe-gigan%C8%9Bii-tehnologiei-%C3%AEn-ceea-ce-prive%C8%99te-costul-%C8%99i-performan%C8%9Ba/), dar... pe care o [imbunatateste](https://epoch.ai/gradient-updates/how-has-deepseek-improved-the-transformer-architecture) considerabil(prin inovatiile aduse proiectului initial/aflat in circulatie, urcand stacheta pe scara evolutiva!), atingand nivelele [ridicate](https://infobrand.ro/deepseek/) de performanta(etalate de modelele actuale  de top), cu un consum [redus](https://codingmall.com/knowledge-base/25-global/248227-care-sunt-avantajele-utilizrii-modelelor-distilate-precum-deepseek-r1-distill-qwen-7b)(in special de timp-GPU/energie) de resurse de calcul(deci intr-un mod mult mai eficient!), fara un sacrificiu la nivelul / de acuratete/precizie(**nota:** desigur, puteti sa vedeti [***distilarea***](https://dexonline.ro/definitie/distilare), ca un sinonim pt un proces de [***separare***](https://www.researchgate.net/figure/Architectures-of-the-Linformer-layer-and-its-components-Left-to-right-scaled_fig2_352209326), in vederea unei [***filtrari|oprire/retinere doar a fractiei utile***](https://dexonline.ro/definitie/filtrare/definitii) ulterioare....insa aici poate ca ar trebui, sa vedem acest termen, si ca pe/insotit de ... un proces de [*diluare*](https://hotnews.ro/cum-a-fost-distilat-deepseek-modelul-care-a-suprins-lumea-ai-tarul-lui-trump-din-domeniu-veti-auzi-multe-despre-aceasta-tehnica-nu-cred-ca-openai-este-prea-fer-1889941)/pierdere a concentratiei/preciziei in favoarea <ins>reducerii/restrangerii</ins> marimii modelului si implicit a latentei/intarzierii/duratei de procesare sale).

***Nota***:
<br/>Tehnica â€<ins>distilÄƒrii</ins>â€ este folositÄƒ de dezvoltatori pentru a profita de un model mai **mare**(**LLM**) È™i mai **performant** â€pentru a [***calibra***](https://dexonline.ro/definitie/calibra/definitii) / [***optimiza***](https://www.explicativ.com/p/tribuna-internationala-deepseek-schimba), deci de a reduce/restrange(**mare**->la->***mic***), un model mai ***mic***(**LM**), permiÈ›Ã¢ndu-i acestuia din urma(deci **LM**-ului), sÄƒ obÈ›inÄƒ ***performanÈ›e-similare***(cu cele ale primului=**LLM**) la o anumitÄƒ sarcinÄƒ(**task**) datÄƒ/focusatÄƒ. 
<br/>Acest proces poate <ins>reduce</ins> semnificativ atÃ¢t <ins>costurile</ins>, cÃ¢t È™i <ins>latenÈ›a</ins>, deoarece modelele mai ***mici***(**LM**-urile) sunt de obicei mai <ins>eficiente</ins>â€, potrivit platformei OpenAI.
<br/>
 - Recomand cu tarie sa lecturati acest topic/tag-ul [*Alegerea Ã®ntre raÈ›ionament(**R**) È™i lanÈ› de gÃ¢ndire(**CoT**)*](https://docs.getkiln.ai/docs/guide-train-a-reasoning-model#choosing-between-reasoning-and-chain-of-thought), subiect oferit/discutat/incorporat in cadrul articolului [*Ghid: AntreneazÄƒ un model-de-raÈ›ionament-**R**(ex.**DeepSeek-R1** sau **OpenAI_o3***)](https://docs.getkiln.ai/docs/guide-train-a-reasoning-model), ca parte a [*documentatiei **Kiln**-AI*](https://docs.getkiln.ai/)(instrument rapid de prototipare-AI È™i de colaborare-cu-ds/setul de date).
<br/>*OBS*: ***Kiln**-AI* este cel mai simplu instrument pentru:

    - ğŸ›ï¸ ***Reglaj fin*** : reglaj-fin(**FT**) zero-code(fara a fi neaparata nevoie sa stiti sa scrieti cod) pentru **Llama**, **GPT4o** È™i **Mixtral**.
  <br/>Implementarea automatÄƒ(fara interventia utilizatorului) fÄƒrÄƒ-server a modelelor.
    - ğŸ¤– ***Generare de date sintetice*** : generaÈ›i/sintetizati/creati seturi de date(**dataset-uri) de antrenament(*ds*-uri <ins>sintetice/artificiale de buna-practica ci/si nu personale/specifice</ins>) cu instrumentele **Kiln** vizuale interactive.
    - ğŸ¤ ***Colaborare Ã®n echipÄƒ*** : controlul versiunii bazat pe **Git** pentru seturile <ins>dvs.</ins> de date AI(**AI-ds**).
   <br/>InterfaÈ›a de utilizare intuitivÄƒ faciliteazÄƒ colaborarea cu **QA**(Queries&Answers), **PM**(ProjectManagement) È™i experÈ›i Ã®n domeniu pe date-structurate/tabelate(exemple/mostre, solicitÄƒri, evaluÄƒri, feedback, probleme etc.).<br/>

Pana la aparitia [**DeepSeek**](https://en.wikipedia.org/wiki/DeepSeek), existau **2** legi(sau mai bine spus 2 momente) de scalare(ajustare/modificare a lungimii/modelului): **pre**-***training*** È™i **post**-***training***.

[**Deepseek**](https://www.deepseek.com/) propune si introduce o a **3**-a lege(un al 3-lea moment) de scalare si anume [**inferenta**](https://www.wikiwand.com/ro/articles/Inferen%C8%9Ba_bayesian%C4%83) in timpul testarii(**intra**-testare).

[**DeepSeek**](https://deepseekcoder.github.io/) este un model care se bazeazÄƒ pe ceea ce se numeÈ™te â€[***calcul Ã®n timp de inferenÈ›Äƒ***](https://www.mpt.upt.ro/doc/curs/gp/Sisteme_inteligente_in_electrotehnica/Inteligenta_artificiala_si_Retele_neuronale_cap1.pdf)â€(asta Ã®nseamnÄƒ cÄƒ â€***pentru fiecare interogare, se activeazÄƒ doar cele mai relevante pÄƒrÈ›i ale modelului***â€).

Asadar [**DeepSeek**](https://github.com/deepseek-ai/DeepSeek-V3) la momentul interogarii, utilizeaza/activeaza ***doar***, **cele mai relevante parti ale modelului**, lucru care duce in final la economii de putere de calcul(astfel ca [nu mai sunt necesare](https://context.reverso.net/traducere/engleza-romana/inference) capacitati mari de calcul si deci, se face astfel, pe cale de consecinta, o economie insemnata de bani, prin costurile scazute necesar a fi efectuate, pt achizitia de GPU-uri scumpe, de inalta performanta). Prin urmare, aceastÄƒ tehnologie necesitÄƒ si mai puÈ›inÄƒ energie(din nou economie de bani).

[**DeepSeek**](https://api-docs.deepseek.com/news/news1120) a construit/instruit/invatat/antrenat(**training**) modelul folosind cipuri din familia [***A100***](https://www.nvidia.com/en-us/data-center/a100/)(dar cu/de capacitate redusÄƒ, gen [Nvidia H800](https://medium.com/@KarlHavard/performance-comparison-nvidia-a100-h100-h800-04db98c58648)) de la **Nvidia**.

Asadar, dat fiind consumul redus de resurse, acum, LLM-ul [**DeepSeek**](https://instashire.com/deepseek-r1-the-ai-powerhouse-redefining-possibilty/) poate fi folosit cu success(folosind un server local de LLM-uri, cum este Ollama) si(daca nu cumva... cu precadere) in medii **locale**(unde dotarile **GPU** sunt mai reduse).

[**DeepSeek**](https://docsbot.ai/models/compare/deepseek-r1/deepseek-v3) a lansat un model care rivalizeazÄƒ cu **ChatGPT** de la ***OpenAI*** È™i **Llama 3.1** de la ***Meta***(insa cu/de cost[uri] scazut[e]!!!).

Domnul [**Fahd Mirza**](https://www.youtube.com/channel/UCPix8N6PMRI4KzgyjuZeF0g) a prezentat cateva [lucruri](https://github.com/fahdmirza/deepseekr1) [interesante](https://www.fahdmirza.com/), legate de [**DeepSeek**](https://huggingface.co/deepseek-ai)([V1](https://saharalabs.ai/blog/understanding-deepseek),[V1.5](https://github.com/deepseek-ai/DeepSeek-Prover-V1.5),[V2](https://www.reddit.com/r/LocalLLaMA/comments/1clkld3/deepseekv2_a_strong_economical_and_efficient/),[V2.5](https://api-docs.deepseek.com/news/news0905),[V3](https://medium.com/@galhyams/deepseek-v3-and-r1-architecture-5e5ae796c7a9),[R1](https://www.unite.ai/ro/deepseek-r1-transformarea-ra%C8%9Bionamentului-ai-cu-%C3%AEnv%C4%83%C8%9Bare-prin-%C3%AEnt%C4%83rire/)), pe [***Youtube***](https://www.youtube.com/results?search_query=Fahd+Mirza+DeepSeek):


 - [Run DeepSeek Janus Pro(1B) on CPU Locally - Image Understanding and Creation](https://www.youtube.com/watch?v=kfN1w_4Zg2E&ab_channel=FahdMirza)(multi-modal)<br/>**Janus-Pro 1B** - este un cadru ***autoregresiv***, care unificÄƒ, ***Ã®nÈ›elegerea***(imaginii....deci **img**2**txt**) È™i/impreuna cu ***generarea***(creaza imagine din/cf. text-descriptiv ... deci **txt**2**img**) - multimodalÄƒ(adica/deci/=**img**&**txt**)
 - [How-To Run **DeepSeek R1(70B)** Locally with **Best GUI** Frontend](https://www.youtube.com/watch?v=b2DBWKBJj3Q&ab_channel=FahdMirza)
 - [Run **DeepSeek R1(32B)** with **Ollama** and **Cline**(agent-*VSc*) in *VScode* - 100% Local Solution](https://www.youtube.com/watch?v=oeBDn6vclz0&t=0s&ab_channel=FahdMirza)
 - [How-To Use **DeepSeek Reasoner(R1)** in API in **Code Easily**](https://www.youtube.com/watch?v=WbKa-gxVybA&ab_channel=FahdMirza)(acesta este [codul](https://github.com/fahdmirza/deepseekr1) utilizat!)
 - [**DeepSeek** Drops **Janus Pro 7B** - Install Locally with Thorough Testing](https://www.youtube.com/watch?v=bWon3I2bGhg&ab_channel=FahdMirza)
 - [Install **DeepSeek-R1 32B** Locally - Best Reasoning Distilled Model So Far](https://www.youtube.com/watch?v=BTNZ1tmVkzA&ab_channel=FahdMirza)
 - [How-To Increase Context Length of **DeepSeek-R1(32B)** model in **Ollama**](https://www.youtube.com/watch?v=BDwM93nhdD4&ab_channel=FahdMirza)
 - [**DeepSeek R1(R1-Zero si R1)** - Indepth Hands-on Review on Language, Coding, Math](https://www.youtube.com/watch?v=x-W56bxJws0&ab_channel=FahdMirza)
 - [**DeepSeek-V2.5-1210**: The Final Version - Test Thoroughly on Math, Coding, Text](https://www.youtube.com/watch?v=h6mzItl32n8&ab_channel=FahdMirza)
 - [**DeepSeek V3** Thorough Testing - Better Than **GPT-4o** and **Claude Sonnet** in Price and Performance](https://www.youtube.com/watch?v=vz1Cs9CpxOg&ab_channel=FahdMirza)
 - [**DeepSeek Coder v2 Lite Instruct** - Local Installation - Beats **GPT-4** In Coding](https://www.youtube.com/watch?v=rlxsDC9aza0&ab_channel=FahdMirza)
   <br/>**DeepSeek-Coder-V2** - este un model de limbaj de codare/codificare(scriere de cod = coder) Mixture-of-Experts(**MoE**), open source,
   <br/>care atinge performanÈ›e comparabile cu **GPT4-Turbo**, Ã®n sarcini specifice codului/codarii(scrierii automate de cod = coder)
 - [How-To Run **DeepSeek V3(GGUF K-XS q5)** Locally on CPU or GPU](https://www.youtube.com/watch?v=uMWPXFDaXBM&ab_channel=FahdMirza)
 - [**DeepSeek R1 Lite Preview** with **DeepThink** - Hands-on Demo](https://www.youtube.com/watch?v=1WArHOSq--8&ab_channel=FahdMirza)
 - [**DeepSeek-R1** with **Continue**(un agent de codare al *VScode*) and **Ollama** - Free, Local and Private](https://www.youtube.com/watch?v=-q-3ghi4A8E&ab_channel=FahdMirza)
 - [A Step-by-Step Guide to Install **DeepSeek-R1** Locally with **Ollama**, ***vLLM*** or ***Transformers***](https://dev.to/nodeshiftcloud/a-step-by-step-guide-to-install-deepseek-r1-locally-with-ollama-vllm-or-transformers-44a1)
 - [Comparison of **DeepSeek V3** vs **Claude Sonnet** vs **GPT-4o** on *Real-World* Task](https://www.youtube.com/watch?v=22EQ9M9SKK0&ab_channel=FahdMirza)
   <br/>Acest videoclip Ã®mpÄƒrtÄƒÈ™eÈ™te rezultatul ***testÄƒrii***, a 3 modele de AI, de top(**DS-V3**, **CS**, **GPT-4o**), pe un caz de utilizare real, din producÈ›ie, Ã®n termeni de **cost**, **timp**, **funcÈ›ionalitate**, [**CoT**](https://www.ibm.com/think/topics/chain-of-thoughts)=lant de gandire=rationament=cum a gandit, de a ajuns la rezultatul afisat, la final [etc.](https://www.promptingguide.ai/techniques/cot) 
 - [How To Install and Run **DeepSeek Coder(1.3B base)**](https://www.youtube.com/watch?v=DwPxCtO-ZU0&ab_channel=FahdMirza)
 - [Install **DeepSeek Janus(1.3B)** Locally - **T2I** and **Vision** - Beats **DALL-E 2** & **SDXL** in Image Generation](https://www.youtube.com/watch?v=uH2SWux7rnQ&ab_channel=FahdMirza)
  <br/>ğŸš€**Janus** de la ***Deepseek*** - este un cadru care se refera la o ***Ã®nÈ›elegere*** a imaginii(si descrierea textuala a ceea ce se vede in imagine=**img**2**txt**) impreuna cu/unificatÄƒ cu/È™i o ***generare*** **MLLM** de imagine (bazata pe un text-descriptiv a imaginii = **txt**2**img**).
  <br/>ğŸš€ Acest cadru(**Janus**) este sponsorizat/ajutat de/se bazeaza pe **AgentQL**, care este un limbaj de interogare, bazat pe AI, pt. obÈ›inerea de ***date structurate***(tabele ce contin datele filtrate/capturate/[scrapping](https://www.avocatoo.ro/blog/este-data-scraping-ul-legal)) din ***pagini web(live)***
 - [**DeepSeek V2** - Strong Economical ***LLM***](https://www.youtube.com/watch?v=AvEGaqFvnYs&ab_channel=FahdMirza)(and Efficient MoE)
 - [Run **DeepSeek R1(32B)** with **Ollama** and **Cline**(agent de codare pt *VSc*) in **VScode** - 100% Local Solution](https://www.youtube.com/watch?v=oeBDn6vclz0&ab_channel=FahdMirza)
 - [Install JanusFlow 1.3B Locally - Image Understanding and Generation in a Single Model](https://www.youtube.com/watch?v=P2jlL-Zmw-g&ab_channel=FahdMirza) <br/>(**JanusFlow** - este un cadru puternic, care unificÄƒ, ***Ã®nÈ›elegerea*** imaginilor È™i/impreuna cu ***generarea imaginilor***, Ã®ntr-un singur model)
 - [How to Set Up and Run DeepSeek R1 Locally With Ollama](https://www.datacamp.com/tutorial/deepseek-r1-ollama)
 - [Deepseek-LLM:7b-chat rurnning on Ollama](https://ollama.com/library/deepseek-llm:7b-chat);
   <br/>Un model lingvistic(**DeepSeek-LLM**) avansat creat cu 2 trilioane de jetoane(bilingve=2 limbi naturale, una fiind engleza desigur!)
 - [Rularea localÄƒ a **DeepSeek Coder R1**, cu ***Ollama*** â€“ Ghid final!](https://www.youtube.com/watch?v=JpWHzAqjuBo&ab_channel=DecodingDataScience)
   <br/>DoriÈ›i sÄƒ rulaÈ›i **DeepSeek Coder R1**, local?
   <br/>Ãn acest videoclip, veti afla cum sÄƒ configuraÈ›i È™i cum sÄƒ rulaÈ›i **DeepSeek Coder R1**, pe computerul dva, folosind ***Ollama***.
 - [...](https://docsbot.ai/models/compare/deepseek-r1/deepseek-v3)

Desigur, pe **Google**, gasiti/descoperiti o sumedenie de alte [articole](https://www.tiktok.com/@iamleorobles/video/7463886995085987114) legate de [**DeepSeek**](https://noerbarry.medium.com/deepseek-v3-offering-new-speed-and-efficiency-in-the-ai-world-outperforming-gpt-4-and-llama-in-559fe6ff1996).

Cu referire la acest subiect, sunt articole interesante, aparute in presa, publicate de regula in [revistele](https://medium.com/@thesab/how-deepseek-overtook-chatgpt-the-rise-of-chinas-ai-powerhouse-bfd1a0062161) online de profil, cum este cazul [**Medium**](https://medium.com/@sahin.samia/deepseek-r1-explained-pioneering-the-next-era-of-reasoning-driven-ai-3eeb5ac4d4a0), **Nature**,... dar publicate si de posturi de televiziune(si nu numai), cum sunt [**BBC**](https://www.bbc.com/news/articles/cd643wx888qo), [**CNN**](https://www.cnn.com/2025/01/27/tech/deepseek-stocks-ai-china/index.html), ...

**Pareri [Pro](https://hotnews.ro/aplicatia-chinezeasca-de-inteligenta-artificiala-sustine-ca-a-fost-victima-unui-atac-cibernetic-la-scara-larga-ce-este-deepseek-1888748) si [Contra](https://www.rfi.fr/ro/interna%C5%A3ional/20250128-expert-it-despre-deepseek-s%C4%83-dezvol%C8%9Bi-un-model-cu-asemenea-rezultate-%C8%99i-la-costuri-sc%C4%83zute-este-uluitor) privind [viitorul](https://distilabel.argilla.io/dev/sections/pipeline_samples/papers/deepseek_prover/) acestei [noii](https://ollama.com/library/deepseek-llm) tehnologii:**

Unii experÈ›i au lÄƒudat performanÈ›ele [***DeepSeek***](https://medium.com/@kirill_86245/how-good-is-deepseek-r1-lite-preview-at-reasoning-403b582d24ca), remarcabilul investitor Ã®n tehnologie **Marc Andreessen** scriind pe reteaua de socializare **X**, pe 24 ianuarie 2025: â€[DeepSeek R1](https://www.datacamp.com/blog/deepseek-r1-lite-preview) este una dintre cele mai uimitoare È™i impresionante [descoperiri](https://docsbot.ai/models/compare/deepseek-v3/o1) pe care le-am vÄƒzut vreodatÄƒ - È™i ca [sursÄƒ deschisÄƒ](https://epoch.ai/gradient-updates/how-has-deepseek-improved-the-transformer-architecture), un [dar profund](https://www.mygreatlearning.com/blog/deepseek-r1-features-use-cases/) pentru lumeâ€.

Ãntr-o declaraÈ›ie pentru **CBS News**, **Nvidia** a lÄƒudat [***DeepSeek***](https://medium.com/@thomas_reid/a-quick-test-of-deepseeks-new-r1-lite-preview-model-7683b5561ad1).

â€Munca [DeepSeek](https://github.com/deepseek-ai/DeepSeek-R1) ilustreazÄƒ modul Ã®n care pot fi create noi modele folosind aceastÄƒ [tehnicÄƒ](https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf), valorificÃ¢nd modelele disponibile pe scarÄƒ largÄƒ È™i calculul care este pe deplin conform cu controlul exporturilorâ€.

Cu toate acestea, **Ives** s-a declarat sceptic cÄƒ serviciul va cÃ¢È™tiga teren Ã®n rÃ¢ndul marilor Ã®ntreprinderi americane.

â€Nici-o corporatie din **Global-2000**-SUA nu va folosi un start-up chinez [***DeepSeek***](https://www.analyticsvidhya.com/blog/2025/01/deepseek-v3-vs-gpt-4o-vs-llama-3-3-70b/) pentru a-È™i lansa infrastructura È™i cazurile de utilizare a **AI**â€, a scris **Ives**.
<br/>â€PÃ¢nÄƒ la urmÄƒ, existÄƒ o singurÄƒ companie producÄƒtoare de cipuri din lume care lanseazÄƒ cazuri de utilizare autonome, robotice È™i **AI** mai largi È™i aceasta este **Nvidia**â€.

<details>
<summary>Incep sa aparÄƒ/curgÄƒ din ce in ce mai multe evaluari ale/articole/tuitoriale despre/legate de <b>DeepSeek</b>...</summary>

 - [Oamenii de È™tiinÈ›Äƒ se Ã®ntÃ¢lnesc la **DeepSeek**: cum folosesc modelul AI de succes](https://www.nature.com/articles/d41586-025-00275-0)
 - [ÃnÈ›elegerea capacitÄƒÈ›ilor modelelor de limbÄƒ mari **DeepSeek-R1**](https://www.digitalocean.com/community/tutorials/deepseek-r1-large-language-model-capabilities)
 - [ÃnvÄƒÈ›area prin Ã®ntÄƒrire(**RL**) se Ã®ncÄƒlzeÈ™te](https://www.deeplearning.ai/the-batch/how-deepseek-r1-and-kimi-k1-5-use-reinforcement-learning-to-improve-reasoning/)
 - [**DeepSeek** explicat: ce este DS È™i este sigur de utilizat?](https://ai.nd.edu/news/deepseek-explained-what-is-it-and-is-it-safe-to-use/)
 - [Cea mai recentÄƒ descoperire a **DeepSeek** este redefinirea cursei **AI**](https://www.csis.org/analysis/deepseeks-latest-breakthrough-redefining-ai-race)
 - [Dezbateri **DeepSeek**: Conducerea chinezeascÄƒ Ã®n ceea ce priveÈ™te costul, costul real al instruirii, impactul marjei modelului Ã®nchis CreÈ™terea preÈ›urilor H100, preÈ›uri subvenÈ›ionate prin inferenÈ›Äƒ, controale la export, Multi-head Latent Attention(**MLA**)](https://semianalysis.com/2025/01/31/deepseek-debates/)
 - [Modelul-**AI** ieftin È™i deschis al Chinei-**DeepSeek** Ã®i entuziasmeazÄƒ pe oamenii de È™tiinÈ›Äƒ](https://www.nature.com/articles/d41586-025-00229-6)
 - [**DeepSeek-R1** vs **DeepSeek-V3**: comparaÈ›ie detaliatÄƒ](https://www.analyticsvidhya.com/blog/2025/02/deepseek-r1-vs-deepseek-v3/)
 - [ÃnÈ›elegerea lucrÄƒrii **DeepSeek-R1**: Ghid pentru Ã®ncepÄƒtori](https://medium.com/data-science-in-your-pocket/understanding-deepseek-r1-paper-beginners-guide-e86f83fda796)
 - [ArhitecturÄƒ **DeepSeek-V3** (È™i **DeepSeek-R1**!)](https://medium.com/@galhyams/deepseek-v3-and-r1-architecture-5e5ae796c7a9)
 - [**DeepSeek-Coder**: CÃ¢nd **LLM**-ul Ã®ntÃ¢lneÈ™te programarea â€” Mai bine decÃ¢t **GPT 3.5**?](https://medium.com/@tanalpha-aditya/deepseek-coder-when-the-llm-meets-programming-better-than-gpt-3-5-054cf85e3493)
 - [**DeepSeek**: Ãmbinarea performanÈ›ei È™i eficienÈ›ei Ã®n **AI** modernÄƒ](https://medium.com/@nandinilreddy/deepseek-bridging-performance-and-efficiency-in-modern-ai-106181a85693)
 - [EP148: **DeepSeek 1-Pager**](https://blog.bytebytego.com/p/ep148-deepseek-1-pager)
 - [***Pentagonul-SUA*** blocheazÄƒ **DeepSeek-AI** dupÄƒ ce angajaÈ›ii au descoperit cÄƒ se conecteazÄƒ la servere ***chineze***](https://www.firstpost.com/tech/us-pentagon-blocks-deepseek-ai-after-employees-found-connecting-to-chinese-servers-13858194.html)
 - [**Open-R1**: o reproducere complet deschisÄƒ a **DeepSeek-R1**](https://huggingface.co/blog/open-r1)
 - [**DeepSeek-R1** a explicat: Pionierat Ã®n urmÄƒtoarea erÄƒ a inteligenÈ›ei artificiale(**AI**) bazate pe raÈ›ionament](https://medium.com/@sahin.samia/deepseek-r1-explained-pioneering-the-next-era-of-reasoning-driven-ai-3eeb5ac4d4a0)
 - [**DeepSeek** este aici pentru a rÄƒmÃ¢ne pt. ca... **Microsoft(MS)** si **Perplexity** Ã®È™i integreazÄƒ modelul](https://www.pcmag.com/news/deepseek-is-here-to-stay-as-microsoft-perplexity-integrate-its-model)
 - [**DeepSeek-R1**: Prezentare tehnicÄƒ a arhitecturii È™i inovaÈ›iilor sale](https://www.geeksforgeeks.org/deepseek-r1-technical-overview-of-its-architecture-and-innovations/)
 - [Reglare-finÄƒ(**FT**) **DeepSeek-R1** (model de raÈ›ionament)](https://www.datacamp.com/tutorial/fine-tuning-deepseek-r1-reasoning-model)
 - [Raport tehnic: Analiza impactului **DeepSeek-R1** asupra dezvoltÄƒrii **AI**](https://www.researchgate.net/publication/388484582_Technical_Report_Analyzing_DeepSeek-R1's_Impact_on_AI_Development)
 - [**DeepSeek-R1** + **Sonnet**](https://medium.com/ingeniouslysimple/deepseek-r1-sonnet-ccd01a0f345b)
 - [Partea-Ãntunecata profunda a **DeepSeek**: Atacuri de reglare-fina impotriva alinierii de siguranta a modelelor **CoT**-*Enabled*](https://arxiv.org/pdf/2502.01225)
 - [Raport tehnic **DeepSeek-V3**](https://arxiv.org/html/2412.19437v1)
 - [Reglarea-finÄƒ(**FT**) a **Deepseek** este necesara sau este inutilÄƒ?](https://www.reddit.com/r/LocalLLaMA/comments/1i9541o/fine_tuning_deepseek_or_is_it_unnecessary/)
 - [**DeepSeek** tocmai a lansat ((DeepSeek-VL2-Small** - Model **MoE**-*Vision* - InstalaÈ›i local](https://www.youtube.com/watch?v=eiWB_zHWbMs&t=22s&ab_channel=FahdMirza)
   <br/>[HF: **Deepseek-VL2-Small**](https://huggingface.co/deepseek-ai/deepseek-vl2-small);
   <br/>**DeepSeek-VL2** - demonstreazÄƒ capabilitÄƒÈ›i superioare Ã®n diverse sarcini, inclusiv, dar fÄƒrÄƒ a se limita la:
    - rÄƒspunsuri vizuale la Ã®ntrebÄƒri(Visual Question Answering=[**VQA**](https://visualqa.org/)),
    - recunoaÈ™terea opticÄƒ a caracterelor([**OCR**](https://ro.wikipedia.org/wiki/Recunoa%C8%99terea_optic%C4%83_a_caracterelor)),
    - Ã®nÈ›elegerea(**U**nderstanding) ...
        - **d**ocumentelor
        - **t**abelului
        - **d**iagramelor È™i
    - [Ã®mpÄƒmÃ¢ntarea vizualÄƒ/Visual Grounding(**VG**)](https://paperswithcode.com/task/visual-grounding/codeless).

      Visual Grounding (**VG**) are scopul de a *localiza cel mai relevant <ins>obiect</ins> sau regiune dintr-o imagine*, pe baza unei interogÄƒri(**Q**) Ã®n limbaj natural(**NL**).

      Interogarea(**QNL**) poate fi
        - o **f***razÄƒ*(deci mai multe *propozitii*...),
        - o **p***ropoziÈ›ie*(singulara sau a unei/dintr-o fraza) sau chiar...
        - un **d***ialog* cu mai multe *runde*(*fraze*) / *multi-round **d**ialog*.

      ExistÄƒ trei provocÄƒri/*obiective* principale Ã®n (scenele-imagine analizate de/in...)**VG**:
        - Care este *accentul principal* Ã®ntr-o interogare(**QNL**)?
        - Cum sÄƒ *Ã®nÈ›elegi o imagine*(separarea/segmentarea si etichetarea obiectelor)?
        - Cum se *localizeazÄƒ un obiect*(localizarea in/locul din lumea-reala reprezentata in/de imagine - unde se afla obiectul)?

 - [CF - catalog LLM-uri expuse](https://developers.cloudflare.com/workers-ai/models/) & [CF - tutoriale](https://developers.cloudflare.com/workers-ai/tutorials/) & [CF - DeepSeek GW](https://developers.cloudflare.com/ai-gateway/providers/deepseek/)
 - [AntreneazÄƒ-È›i propriul model-AI de raÈ›ionament Ã®n 30 de minute cu **Deepseek-R1** È™i **Kiln**](https://www.reddit.com/r/LocalLLaMA/comments/1iik4y9/train_your_own_reasoning_model_in_30_minutes_with/)
   <br/>Tocmai a fost lansata o actualizare a **Kiln** pe Github care vÄƒ permite sÄƒ *distilaÈ›i* un model personalizat ajustat de la **Deepseek R1** (sau orice model de raÈ›ionament/lanÈ› de gÃ¢ndire).
   <br/>Ãntregul proces dureazÄƒ doar aproximativ 30 de minute, inclusiv generarea unui *set de date(ds) de antrenament sintetic/generat*.
   <br/>Nu necesitÄƒ codare sau lucru pe linia de comandÄƒ.

    - [Videoclipul](https://github.com/Kiln-AI/Kiln/blob/main/guides/Fine%20Tuning%20LLM%20Models%20Guide.md#step-6-optional-training-on-your-own-infrastructure) ataÈ™at aratÄƒ procesul
    - Documentele videoclipului au un [*ghid pentru distilarea DeepSeek-R1*](https://docs.getkiln.ai/docs/guide-train-a-reasoning-model) dacÄƒ doriÈ›i sÄƒ Ã®l Ã®ncercaÈ›i singur; Aici puteti vedea cum sa alegeti intre modelele [Reasoning si/vs. CoT](https://docs.getkiln.ai/docs/guide-train-a-reasoning-model#choosing-between-reasoning-and-chain-of-thought).
    - IatÄƒ [depozitul Kiln pe Github](https://github.com/Kiln-AI/Kiln) cu tot *codul-sursÄƒ*

   De asemenea, s-a vrut sÄƒ se adauge o mare mulÈ›umire  [*r/localllama*](https://www.reddit.com/r/localllama/)-ului pentru primirea minunatÄƒ la [ultima sa postare/actualizare](https://www.reddit.com/r/LocalLLaMA/comments/1i1ffid/i_accidentally_built_an_open_alternative_to/) . 
   <br/>Aceasta ultima postare inspirÄƒ la continuarea de a se construi mai departe. 
   <br/>Deja sunt aproximativ *30 de Ã®mbunÄƒtÄƒÈ›iri* È™i s-au creat *solicitÄƒri de caracteristici*, care au venit de la oameni(care le-au gÄƒsit prin [*r/localllama*](https://www.reddit.com/r/localllama/)).
   <br/>*Kiln* ruleazÄƒ <ins>local</ins> È™i nu are niciodatÄƒ acces la setul dvs. de date. 
   <br/>[*Unsloth*](https://github.com/Kiln-AI/Kiln/blob/main/guides/Fine%20Tuning%20LLM%20Models%20Guide.md#step-6-optional-training-on-your-own-infrastructure) este pe deplin acceptat dacÄƒ aveÈ›i **GPU**-uri pentru a vÄƒ antrena <ins>local</ins>. 
   <br/>De asemenea, puteÈ›i utiliza, un serviciu de instruire precum **Fireworks** & **OpenAI**, dacÄƒ preferaÈ›i(datele le sunt trimise cu *cheile* dvs., si de asemenea nu exista acces la ele). 
   <br/>DacÄƒ cineva doreÈ™te sÄƒ Ã®ncerce *Kiln*, aici este [depozitul GitHub](https://github.com/Kiln-AI/Kiln) È™i [documentele sunt aici](https://github.com/Kiln-AI/Kiln) . 
   <br/>Ãnceperea este foarte simplÄƒ - este o instalare cu un singur clic pentru a Ã®ncepe configurarea È™i funcÈ›ionarea.

 - [...](https://devpress.csdn.net/user/v_JULY_v)

</details>
   
In speranta ca am mai "[de-mistificat](https://www.linkedin.com/pulse/demystifying-deepseek-healthtech-professionals-ai-alex-g--n76ge/)", subiectul [***DeepSeek***](https://www.reddit.com/r/LocalLLaMA/comments/1ic24e0/now_you_can_use_deepseek_with_mcp_tools/), la final, as dori sa spun, doar faptul ca ... [timpul](https://adasci.org/deepseek-v3-explained-optimizing-efficiency-and-scale/), va fi cel care, [va proba](https://www.youtube.com/watch?v=bAWV_yrqx4w&ab_channel=YannicKilcher), cele spuse mai sus, in rest...sa [auzim](https://huggingface.co/docs/trl/main/en/grpo_trainer) numai de [bine](https://medium.com/@marvelous_catawba_otter_200/detailed-explanation-of-deepseek-r1-method-pure-reinforcement-learning-and-self-evolving-behavior-dced3a31e53a)!!!
