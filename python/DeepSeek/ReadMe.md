Salut,

In acest articol as dori sa aprofundam discutia cu privire la [**DeepSeek**](https://www.stiripesurse.ro/cutremur-in-domeniul-inteligentei-artificiale-ce-este-deepseek-si-de-ce-ii-sperie-pe-investitori_3563231.html)

Pentru inceput as vrea sa va reamintesc cate ceva despre termenul de [**inferenta**](https://ro.wikipedia.org/wiki/Inferen%C8%9B%C4%83).

[**Inferenta**](https://en.wikipedia.org/wiki/Inference) inseamna utilizarea **modelelor AI** pentru a lua **decizii** sau a face **predicții**.

[**Inferenta**](https://ro.wiktionary.org/wiki/inferen%C8%9B%C4%83) necesită un număr semnificativ de GPU(desigur NVIDIA) și rețele de înaltă performanță.

Pana la aparitia [**DeepSeek**](https://en.wikipedia.org/wiki/DeepSeek), existau **2** legi(dar si momente) de scalare(ajustare/modificare a lungimii/modelului): **pre**-***training*** și **post**-***training***.

**Deepseek** propune si introducere o a **3**-a lege si anume [**interferenta**](https://www.wikiwand.com/ro/articles/Inferen%C8%9Ba_bayesian%C4%83) in timpul testarii(**intra**-testare).

**DeepSeek** este un model care se bazează pe ceea ce se numește „***calcul în timp de inferență***”(asta înseamnă că „***activează doar cele mai relevante părți ale modelului lor pentru fiecare interogare***”).

Asadar **DeepSeek** la momentul interogarii, utilizeaza doar **cele mai relevante parti ale modelului**, lucru care duce in final la economii de putere de calcul(astfel ca nu mai sunyt necesare capacitati mari de calcul si deci se face pe cale de consecinta si economie de bani prin costurile scazute necesar a fi efectuate)
Această tehnologie necesită mai puțină energie.

**DeepSeek** a construit modelul folosind cipuri cu capacitate redusă de la Nvidia(Nvidia ***A100***).

**DeepSeek** a lansat un model care rivalizează cu **ChatGPT** de la ***OpenAI*** și **Llama 3.1** de la ***Meta***.
